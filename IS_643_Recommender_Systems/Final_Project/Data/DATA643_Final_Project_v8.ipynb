{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "tstart = time()\n",
    "\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import scipy \n",
    "\n",
    "import datetime\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1,000,000 Records\n",
    "Ubuntu 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Some data exploration using SparkSQL\n",
    "#Source adapted from http://spark.apache.org/docs/latest/sql-programming-guide.html#dataframes\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loading 1,000, 000 Movie lens data directly from github\n",
    "path = \"https://raw.githubusercontent.com/ppadebettu/CUNY/Master/IS_643_Recommender_Systems/Final_Project/Data/\"\n",
    "movies_fname = 'movies.dat'\n",
    "url = path + movies_fname\n",
    "pd_movies = pd.read_csv(url, sep = \":\" , header = None, na_values='NaN', usecols = [0,2], names = ['movieid', 'movietitle'])\n",
    "\n",
    "users_fname = 'users.dat'\n",
    "url = path + users_fname\n",
    "pd_users = pd.read_csv(url, sep = \":\" , header = None, na_values='NaN', usecols = [0,2,4,6,8], \n",
    "                       names = ['userid', 'gender', 'age', 'occupation', 'zipcode'])\n",
    "\n",
    "ratings_fname = 'ratings.dat'\n",
    "url = path + ratings_fname\n",
    "pd_ratings = pd.read_csv(url, sep = \":\" , header = None, na_values='NaN', usecols = [0,2,4,6], \n",
    "                       names = ['userid', 'movieid', 'rating', 'timestamp'])\n",
    "\n",
    "result = pd.merge(pd_ratings,pd_movies, on = ['movieid'] )\n",
    "movielens = pd.merge(result,pd_users, on = ['userid'] )\n",
    "\n",
    "\n",
    "# Code to add the new columns that will contain the context data that is obtained from the timestamp\n",
    "\n",
    "def fdate(x):   \n",
    "    return datetime.datetime.fromtimestamp(\n",
    "        int(str(x['timestamp']))).strftime('%Y-%m-%d') \n",
    "\n",
    "def ftime(x):   \n",
    "    return datetime.datetime.fromtimestamp(\n",
    "        int(str(x['timestamp']))).strftime('%H:%M:%S') \n",
    "\n",
    "def fweekday(x):   \n",
    "    \n",
    "    if (datetime.datetime.fromtimestamp(int(str(x['timestamp']))).weekday() >= 4):\n",
    "        return 'Weekend'\n",
    "    else:\n",
    "        return 'Weekday'\n",
    "    \n",
    "def fagegroup(x):   \n",
    "    \n",
    "    if (x['age'] >= 45):\n",
    "        return '45+'\n",
    "    \n",
    "    elif (x['age'] >= 30):\n",
    "        return '30-44'\n",
    "    \n",
    "    elif (x['age'] >= 19):\n",
    "        return '19-29'\n",
    "    else:\n",
    "        return 'below 18' \n",
    "    \n",
    "   \n",
    "def ftimeofday(x): \n",
    "    \n",
    "    t = datetime.datetime.fromtimestamp(int(str(x['timestamp']))).strftime('%H:%M:%S')\n",
    "    \n",
    "    if (t >= '23:00:00'):\n",
    "        return 'night'\n",
    "    \n",
    "    elif (t >= '18:00:00'):\n",
    "        return 'evening'\n",
    "    \n",
    "    elif (t >= '12:00:00'):\n",
    "        return 'afternoon'\n",
    "    \n",
    "    elif (t >= '08:00:00'):\n",
    "        return 'morning'\n",
    "    \n",
    "    else:\n",
    "        return 'night'\n",
    "    \n",
    "def flocation(x):   \n",
    "    \n",
    "    start = datetime.datetime.strptime(x['date'], '%Y-%m-%d')\n",
    "    end = datetime.datetime.strptime(x['releasedate'], '%d-%b-%Y')\n",
    "    \n",
    "    if start - end >= datetime.timedelta(180):\n",
    "        return 'home'\n",
    "    else:\n",
    "        return 'theater'       \n",
    "    \n",
    "    \n",
    "movielens['date'] = movielens.apply(fdate, axis=1)\n",
    "movielens['time'] = movielens.apply(ftime, axis=1)\n",
    "movielens['weekday'] = movielens.apply(fweekday, axis=1)\n",
    "#pandas_df['agegroup'] = pandas_df.apply(fagegroup, axis=1)  \n",
    "\n",
    "movielens['timeofday'] = movielens.apply(ftimeofday, axis=1)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000209, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movielens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>movieid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movietitle</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>weekday</th>\n",
       "      <th>timeofday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>2000-12-31</td>\n",
       "      <td>17:12:40</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "      <td>James and the Giant Peach (1996)</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>2000-12-31</td>\n",
       "      <td>17:35:09</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "      <td>My Fair Lady (1964)</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>2000-12-31</td>\n",
       "      <td>17:32:48</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "      <td>Erin Brockovich (2000)</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>2000-12-31</td>\n",
       "      <td>17:04:35</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>2001-01-06</td>\n",
       "      <td>18:38:11</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  movieid  rating  timestamp                              movietitle  \\\n",
       "0       1     1193       5  978300760  One Flew Over the Cuckoo's Nest (1975)   \n",
       "1       1      661       3  978302109        James and the Giant Peach (1996)   \n",
       "2       1      914       3  978301968                     My Fair Lady (1964)   \n",
       "3       1     3408       4  978300275                  Erin Brockovich (2000)   \n",
       "4       1     2355       5  978824291                    Bug's Life, A (1998)   \n",
       "\n",
       "  gender  age  occupation zipcode        date      time  weekday  timeofday  \n",
       "0      F    1          10   48067  2000-12-31  17:12:40  Weekend  afternoon  \n",
       "1      F    1          10   48067  2000-12-31  17:35:09  Weekend  afternoon  \n",
       "2      F    1          10   48067  2000-12-31  17:32:48  Weekend  afternoon  \n",
       "3      F    1          10   48067  2000-12-31  17:04:35  Weekend  afternoon  \n",
       "4      F    1          10   48067  2001-01-06  18:38:11  Weekend    evening  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movielens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3706, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>movietitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1193</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>661</td>\n",
       "      <td>James and the Giant Peach (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>914</td>\n",
       "      <td>My Fair Lady (1964)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3408</td>\n",
       "      <td>Erin Brockovich (2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2355</td>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieid                              movietitle\n",
       "0     1193  One Flew Over the Cuckoo's Nest (1975)\n",
       "1      661        James and the Giant Peach (1996)\n",
       "2      914                     My Fair Lady (1964)\n",
       "3     3408                  Erin Brockovich (2000)\n",
       "4     2355                    Bug's Life, A (1998)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get movie titles\n",
    "movies_titles = movielens[['movieid', 'movietitle']]\n",
    "movies_titles =movies_titles.drop_duplicates()\n",
    "print movies_titles.shape\n",
    "movies_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movielens = movielens[['userid','movieid','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext = pyspark.sql.SQLContext(sc)\n",
    "movie_rdd = sqlContext.createDataFrame(movielens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userid|movieid|rating|\n",
      "+------+-------+------+\n",
      "|     1|   1193|     5|\n",
      "|     1|    661|     3|\n",
      "|     1|    914|     3|\n",
      "|     1|   3408|     4|\n",
      "|     1|   2355|     5|\n",
      "+------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_rdd.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(movie_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(userid=1, movieid=1193, rating=5),\n",
       " Row(userid=1, movieid=661, rating=3),\n",
       " Row(userid=1, movieid=914, rating=3),\n",
       " Row(userid=1, movieid=3408, rating=4),\n",
       " Row(userid=1, movieid=2355, rating=5)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split data into training and test datasets\n",
    "training_RDD, validation_RDD, test_RDD = movie_rdd.rdd.randomSplit([6, 2, 2], seed=0L)\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1193), (1, 1287), (1, 2804), (1, 594), (1, 919)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_for_predict_RDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 3408), (1, 2355), (1, 938), (1, 2918), (1, 2018)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_for_predict_RDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(userid=1, movieid=661, rating=3),\n",
       " Row(userid=1, movieid=914, rating=3),\n",
       " Row(userid=1, movieid=1197, rating=3)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 0.884217682053\n",
      "For rank 8 the RMSE is 0.875185078879\n",
      "For rank 12 the RMSE is 0.875303351425\n",
      "The best model was trained with rank 8\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "seed = 5L\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    ratesAndpreds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(ratesAndpreds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print 'For rank %s the RMSE is %s' % (rank, error)\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print 'The best model was trained with rank %s' % best_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((4551, 347), 2.9735000904684004),\n",
       " ((4551, 163), 2.6672770802723273),\n",
       " ((4551, 858), 4.384040013031293)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check our predictions\n",
    "predictions.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((5569, 597), (5.0, 3.972421976074028)),\n",
       " ((967, 597), (5.0, 3.859913585358328)),\n",
       " ((3290, 2688), (3.0, 2.363323866272773))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's compare predictions vs actuals (ratings)\n",
    "ratesAndpreds.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.875154490879\n"
     ]
    }
   ],
   "source": [
    "#Let's test the selected model\n",
    "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "predictions = model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "ratesAndpreds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(ratesAndpreds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print 'For testing data the RMSE is %s' % (error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings: [(998, 242, 4), (998, 51, 3), (998, 465, 1), (998, 86, 2), (998, 222, 3), (998, 274, 4), (998, 1042, 3), (998, 1184, 3), (998, 265, 2), (998, 302, 3)]\n"
     ]
    }
   ],
   "source": [
    "#Create a list of ratings for a new user (998)\n",
    "new_user_ID_1 = 998\n",
    "\n",
    "# The format of each line is (userID, movieID, rating)\n",
    "new_user_ratings_1 = [\n",
    " (998, 242, 4), # Kolya (1996)\n",
    " (998, 51, 3),  # Legends of the Fall (1994)\n",
    " (998, 465, 1),  # Jungle Book, The (1994)\n",
    " (998 , 86, 2), # Remains of the Day, The (1993)\n",
    " (998, 222, 3), # Star Trek: First Contact (1996)\n",
    " (998, 274, 4), # Sabrina (1995)\n",
    " (998, 1042, 3),  # Just Cause (1995)\n",
    " (998, 1184, 3), # Endless Summer 2, The (1994)\n",
    " (998, 265, 2), # Hunt for Red October, The (1990)\n",
    " (998, 302, 3) # L.A. Confidential (1997)\n",
    "]\n",
    "new_user_ratings_RDD_1 = sc.parallelize(new_user_ratings_1)\n",
    "print 'New user ratings: %s' % new_user_ratings_RDD_1.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge new user ratings to the existing RDD\n",
    "data_with_new_ratings_RDD = movie_rdd.rdd.union(new_user_ratings_RDD_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model trained in 18.885 seconds\n"
     ]
    }
   ],
   "source": [
    "#Train the ALS model using new dataset and all the parameters we selected before\n",
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "new_ratings_model = ALS.train(data_with_new_ratings_RDD, best_rank, seed=seed, \n",
    "                              iterations=iterations, lambda_=regularization_parameter)\n",
    "tt = time() - t0\n",
    "\n",
    "print \"New model trained in %s seconds\" % round(tt,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Getting top recommendations\n",
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings_1) # get just movie IDs\n",
    "# keep just those not on the ID list (thanks Lei Li for spotting the error!)\n",
    "new_user_unrated_movies_RDD = movie_rdd.rdd.filter(lambda x: x[0] not in new_user_ratings_ids)\\\n",
    "                               .map(lambda x:(new_user_ID_1, x[0]))\n",
    "\n",
    "# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
    "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1783, 3.060338282873792),\n",
       " (2575, 3.7763104345544116),\n",
       " (2253, 2.7780416703225352)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
    "# Use distinct() here\n",
    "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.distinct().map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(movieid=1193, movietitle=u\"One Flew Over the Cuckoo's Nest (1975)\"), Row(movieid=661, movietitle=u'James and the Giant Peach (1996)'), Row(movieid=914, movietitle=u'My Fair Lady (1964)')]\n"
     ]
    }
   ],
   "source": [
    "#Get movie titles\n",
    "movies = sqlContext.createDataFrame(movies_titles)\n",
    "print movies.take(3)\n",
    "m = movies.map(lambda x: (int(x[0]),x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1193, u\"One Flew Over the Cuckoo's Nest (1975)\"),\n",
       " (661, u'James and the Giant Peach (1996)')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(572, (5.105234326202673, u'Foreign Student (1994)')),\n",
       " (1851, (5.00454326917589, u'Leather Jacket Love Story (1997)')),\n",
       " (3233, (4.8539271025667805, u'Smashing Time (1967)'))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge movie titles and recommendations for the new user so that the results are meaningful\n",
    "#movies_titles = ratings_data.map(lambda x: (int(x[0]),x[1]))\n",
    "new_user_recommendations_rating_title_RDD = new_user_recommendations_rating_RDD.join(m)\n",
    "new_user_recommendations_rating_title_RDD.distinct().sortBy(lambda x: x[1][0], ascending=False).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Total run time =  5.402 minutes\n"
     ]
    }
   ],
   "source": [
    "print \"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\"\n",
    "tstop = time() - tstart\n",
    "\n",
    "print \"Total run time =  %s minutes\" % round(tstop/60,3)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
